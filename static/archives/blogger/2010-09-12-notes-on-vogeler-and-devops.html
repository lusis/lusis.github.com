--- 
name: notes-on-vogeler-and-devops
layout: post
title: "Notes on #vogeler and #devops"
time: 2010-09-12 03:51:00 -04:00
---
<p><strong><span style="font-size:medium;"><span class="Apple-style-span"  style="color:#FF0000;">UPDATE: There's some additional information about Vogeler in the </span><a href="http://lusislog.blogspot.com/2010/09/follow-up-to-vogeler-post.html"><span class="Apple-style-span"  style="color:#33CC00;">followup post</span></a><span class="Apple-style-span"  style="color:#FF0000;"> to this one: </span></span></strong></p><p><strong><span style="font-size:medium;">Background</span></strong></p><p>So I've been tweeting quite a bit about my current project Vogeler. Essentially it's a basic configuration management database built on RabbitMQ and CouchDB. I had to learn Python for work, we may or may not be using those two technologies so Vogeler was born.</p><p>There's quite a bit of information on Github about it but essentially the basic goals are these:</p><ul><li>Provide a place to store configuration about systems</li><li>Provide a way to update that configuration easily and scalably</li><li>Provide a way for users to EASILY extend it with the information they need</li></ul><p>I'm not doing a default web interface or much else right now. There's three basic components - a server process, a client process and a script runner. The first two don't act as traditional daemons but instead monitor a queue server for messages and act on that.</p><p>In the case of the client, it waits for a command alias and acts on that alias. The results are stuck on another queue for the server. The server sits and monitors that queue. When it sees a message, it takes it and inserts it in the database with some formatting based on the message type. That's it. The server doesn't initiate and connections directly to the clients and neither do the clients talk directly to the server. All messages that the clients see are initiated by the runner script only. </p><p>That's it in a nutshell.</p><p><span style="font-size:medium;"><strong>0.7 release</strong></span></p><p>I just released 0.7 of the library to PyPi (no small feat with a teething two year old and 5 month old) and with it, what I consider the core functionality it needs to be useful for people who really are interested in testing it. Almost everything is configurable now. Server, Client and Runner can specify where each component it needs lives on the network. CouchDB and RabbitMQ are running in different locations from the server process? No problem. Using authentication in CouchDB? You can configure that too. Want to use different RabbitMQ credentials? Got it covered.</p><p>Another big milestone was getting it working with Python 2.6. No distro out there that I know of is using 2.7 which is what I was using to develop Vogeler. The reason I chose 2.7 is that was the version we standardized on and since I was learning a new language and 2.7 was a bridge to 3, I chose that one. But when I went to started looking at trying the client on other machines at home, I realized I didn't want to compile and setup the whole virtualenv thing on each of them. So I got it working with 2.6 which is what Ubuntu is using. For CentOS and RedHat testing, I just used ActivePython 2.7 in /opt/. </p><p><span style="font-size:medium;"><strong>Milestones</strong></span></p><p>As I said 0.7 was a big milestone release for me because of the above things. Now I've got to do some of the stuff I would have done before if I hadn't been learning a new language:</p><ul><li>Unit Tests - These are pretty big for me. Much of my work on Padrino has been as the Test nazi. Your test fails, I'm all up in your grill. </li><li>Refactor - Once the unit tests are done, I can safely being to refactor the codebase. I need to move everything out of a single .py with all the classes. This also paves the way for allowing swappable messaging and persistence layers. This is where unit tests shine, IMHO. Additionally, I'll finish up configuration file setup at this point.</li><li>Logging and Exception handling - I need to setup real loggers and stop using print messages. This is actually pretty easy. Exception handling may come as a result of the refactor but I consider it a distinct milestone.</li><li>Plugin stabilization - I'm still trying to figure out the best way to handle default plugins and what basic document layout I want.</li></ul><p>Once those are done, I should be ready for a 1.0 release however before I cut that release, I have one last test.....</p><p><span style="font-size:medium;"><strong>The EC2 blowout</strong></span></p><p>This is the part I'm most excited about. When I feel like I'm ready to cut 1.0, I plan on spinning up a few hundred EC2 vogeler-client instances of various flavors (RHEL, CentOS, Debian, Ubuntu, Suse...you name it). I'll also stand up distinct RabbitMQ, CouchDB and vogeler-server instances.</p><p>Then I fire off the scripts. Multiple vogeler-runner invocations concurrently from different hosts and distros. I need to work out the final matrix but I'll probably use Hudson to build it. </p><p>While you might think that this is purely for load testing, it's not. Load testing is a part of it but another part is seeing how well Vogeler works as a configuration management database - the intended usage. What better way than to build out a large server farm and see where the real gaps are in the default setup? Additionally, this will allow me to really standardize on some things in the default based on the results.</p><p>At <strong>THAT</strong> point, I cut 1.0 and see what happens.</p><p><span style="font-size:medium;"><strong>How you can help</strong></span></p><p>What I really need help with now is feedback. I've seen about a 100 or so total downloads on PyPi across releases but no feedback on Github yet. That's probably mostly due to such minimal functionality before now and the initial hurdle. I've tried to keep the Github docs up to date. I think if I convert the github markdown to rst and load it on PyPi, that will help.</p><p>I also need advice from real Python developers. I know I'm doing some crazy stupid shit. It's all a part of learning. Know a way to optimize something I'm doing? Please tell me. Is something not working properly? Tell me. I've tried to test in multiple virtualenvs on multiple distros between 2.6 and 2.7 but I just don't know if I've truly isolated each manual test.</p><p>Check the wiki on github and try to install it yourself. Please!</p><p>I'm really excited about how things are coming along and about the project itself. If you have ANY feedback or comments, whatsoever, please pass it on even if it's negative. Feel free to tell me that it's pointless but at least tell me why you think so. While this started out as a way to learn Python, I really think it could be useful to some people and that's kept me going more than anything despite the limited time I've had to work on it (I can't work on it as part of my professional duties for many reasons). I've been trying to balance my duties as a father of two, husband, Padrino team member along with this and I think my commitment (4AM...seriously?) is showing.</p><p>Thanks!</p><div class="blogger-post-footer"><img width='1' height='1' src='https://blogger.googleusercontent.com/tracker/934985301455705990-5334820747864288571?l=lusislog.blogspot.com' alt='' /></div>
